{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Example Using `mlos_core`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fake \"performance\" function.\n",
    "# In an actual application, we would not have access to this function directly.\n",
    "# Instead, we could only measure the outcome by running an experiment, such as timing\n",
    "# a particular run of the system.\n",
    "def f(x):\n",
    "    return (6*x-2)**2*np.sin(12*x-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a domain to evaluate\n",
    "line = np.linspace(0, 1)\n",
    "# evaluate the function\n",
    "values = f(line)\n",
    "# plot the function\n",
    "plt.plot(line, values)\n",
    "plt.xlabel(\"Input (parameter)\")\n",
    "plt.ylabel(\"Objective (i.e. performance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ConfigSpace as CS\n",
    "\n",
    "# Start defining a ConfigurationSpace for the Optimizer to search.\n",
    "input_space = CS.ConfigurationSpace(seed=1234)\n",
    "\n",
    "# Add a single continuous input dimension between 0 and 1.\n",
    "input_space.add_hyperparameter(CS.UniformFloatHyperparameter(name='x', lower=0, upper=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlos_core.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimizer.\n",
    "\n",
    "#optimizer = mlos_core.optimizers.RandomOptimizer(parameter_space=input_space)\n",
    "\n",
    "#optimizer = mlos_core.optimizers.FlamlOptimizer(parameter_space=input_space)\n",
    "\n",
    "optimizer = mlos_core.optimizers.SmacOptimizer(parameter_space=input_space) # , seed=42, n_random_init=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the chosen optimizer\n",
    "optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the actual optimization which will carry out the steps outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(optimizer: mlos_core.optimizers.BaseOptimizer):\n",
    "    # get a new config value suggestion to try from the optimizer.\n",
    "    suggested_value, ctx = optimizer.suggest()\n",
    "    \n",
    "    # suggested value are dictionary-like, keys are input space parameter names\n",
    "    # evaluate target function\n",
    "    target_value = f(suggested_value['x'])\n",
    "    print(suggested_value, \"\\n\", target_value )\n",
    "    print(ctx)\n",
    "    optimizer.register(suggested_value, target_value, ctx)\n",
    "\n",
    "# run for some iterations\n",
    "n_iterations = 15\n",
    "for i in range(n_iterations):\n",
    "    run_optimization(optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 15 iterations, the model is likely to have captured the general shape, but probably not have found the actual optimum since the first few iterations are spent randomly exploring the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.get_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the surrogate function\n",
    "#\n",
    "configs = pd.DataFrame(line.reshape(-1, 1), columns=['x'])\n",
    "surrogate_predictions = optimizer.surrogate_predict(configs)\n",
    "\n",
    "# plot the observations\n",
    "#\n",
    "observations = optimizer.get_observations()\n",
    "plt.scatter(observations.x, observations.score, label='observed points')\n",
    "\n",
    "# plot the true function (usually unknown)\n",
    "#\n",
    "plt.plot(line, values, label='true function')\n",
    "\n",
    "# plot the surrogate\n",
    "#\n",
    "# alpha = optimizer_config.experiment_designer_config.confidence_bound_utility_function_config.alpha\n",
    "# t_values = t.ppf(1 - alpha / 2.0, surrogate_predictions['predicted_value_degrees_of_freedom'])\n",
    "# ci_radii = t_values * np.sqrt(surrogate_predictions['predicted_value_variance'])\n",
    "# value = surrogate_predictions['predicted_value']\n",
    "plt.plot(line, surrogate_predictions, label='surrogate predictions')\n",
    "#plt.fill_between(line, value - ci_radii, value + ci_radii, alpha=.1)\n",
    "#plt.plot(line, -optimizer.experiment_designer.utility_function(optimization_problem.construct_feature_dataframe(pd.DataFrame({'x': line}))), ':', label='utility_function')\n",
    "plt.ylabel(\"Objective function f (performance)\")\n",
    "plt.xlabel(\"Input variable\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the best value according to the current surrogate with the ``optimum`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.get_best_observation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run more iterations to improve the surrogate model and the optimum that is found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for more iterations\n",
    "n_iterations = 50\n",
    "for i in range(n_iterations):\n",
    "    run_optimization(optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some improvement in the optimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.get_best_observation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the surrogate model and optimization process again. The points are colored according to the iteration number, with dark blue points being early in the process and yellow points being later. You can see that at the end of the optimization, the points start to cluster around the optimum.\n",
    "The region to the right is not explored much because the surrogate model predicts that it is not likely to contain the optimum and hence also doesn't have as much accuracy compared to the real function there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the surrogate function\n",
    "#\n",
    "configs = pd.DataFrame(line.reshape(-1, 1), columns=['x'])\n",
    "surrogate_predictions = optimizer.surrogate_predict(configs)\n",
    "\n",
    "# plot the observations\n",
    "#\n",
    "observations = optimizer.get_observations()\n",
    "plt.scatter(observations.x, observations.score, label='observed points')\n",
    "\n",
    "# plot true function (usually unknown)\n",
    "#\n",
    "plt.plot(line, values, label='true function')\n",
    "\n",
    "# plot the surrogate\n",
    "#\n",
    "#ci_raduii = surrogate_predictions['prediction_ci']\n",
    "plt.plot(line, surrogate_predictions, label='surrogate predictions')\n",
    "#plt.fill_between(line, value - ci_radii, value + ci_radii, alpha=.1)\n",
    "#plt.plot(line, -optimizer.utility_function(pd.DataFrame({'x': line})), ':', label='utility_function')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"Objective function f\")\n",
    "ax.set_xlabel(\"Input variable\")\n",
    "bins_axes = ax.twinx()\n",
    "bins_axes.set_ylabel(\"Points sampled\")\n",
    "pd.DataFrame(observations.x).hist(bins=20, ax=bins_axes, alpha=.3, color='k', label=\"count of query points\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcb43bafd5ce954ead015d0d89e27da6852c23ac7a7b5a1213fc2fecbe919e66"
  },
  "kernelspec": {
   "display_name": "Python [conda env:mlos_core] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
